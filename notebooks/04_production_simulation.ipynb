{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 04 - Simulation Production\n",
    "\n",
    "Notebook de simulation du flow de production Chiron.\n",
    "\n",
    "## Étapes\n",
    "1. **Parsing PDF** : Extraction des données (pdfplumber ou Mistral OCR)\n",
    "2. **Pseudonymisation** : (désactivée pour l'instant)\n",
    "3. **Stockage** : (à venir)\n",
    "4. **Génération LLM** : (à venir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-détecter project_root\n",
    "current = Path.cwd()\n",
    "while current != current.parent:\n",
    "    if (current / \"pyproject.toml\").exists():\n",
    "        project_root = current\n",
    "        break\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = project_root / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PDFs disponibles: {[p.name for p in RAW_DIR.glob('*.pdf')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Configuration du Parser\n",
    "\n",
    "Deux options disponibles :\n",
    "- **pdfplumber** : Local, gratuit, rapide (~0.06s/page)\n",
    "- **mistral_ocr** : Cloud, payant (2$/1000 pages), plus robuste (~2s/page)\n",
    "\n",
    "Le choix se fait via :\n",
    "- Variable d'environnement `PDF_PARSER_TYPE` dans `.env`\n",
    "- Ou paramètre explicite `get_parser(ParserType.XXX)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.document import estimate_mistral_cost, get_parser\n",
    "from src.llm.config import settings\n",
    "\n",
    "# Afficher la config actuelle\n",
    "print(f\"Parser configuré dans .env : {settings.pdf_parser_type}\")\n",
    "print(f\"Modèle Mistral OCR : {settings.mistral_ocr_model}\")\n",
    "print(f\"Coût Mistral OCR : {settings.mistral_ocr_cost_per_1000_pages}$/1000 pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation du coût si Mistral OCR\n",
    "pdfs = list(RAW_DIR.glob(\"*.pdf\"))\n",
    "estimate = estimate_mistral_cost(pdfs)\n",
    "print(f\"PDFs à traiter : {len(pdfs)}\")\n",
    "print(f\"Pages totales : {estimate['pages']}\")\n",
    "print(f\"Coût estimé Mistral OCR : ${estimate['cost_usd']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le parser (décommenter celui souhaité)\n",
    "\n",
    "# Option 1: Parser par défaut (depuis .env)\n",
    "parser = get_parser()\n",
    "\n",
    "# Option 2: Forcer pdfplumber (local, gratuit)\n",
    "# parser = get_parser(ParserType.PDFPLUMBER)\n",
    "\n",
    "# Option 3: Forcer Mistral OCR (cloud, payant)\n",
    "# parser = get_parser(ParserType.MISTRAL_OCR)\n",
    "\n",
    "print(f\"Parser sélectionné : {type(parser).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Parsing des PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = {}\n",
    "times = {}\n",
    "\n",
    "for pdf_path in sorted(RAW_DIR.glob(\"*.pdf\")):\n",
    "    eleve_id = pdf_path.stem\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        extractions = parser.parse(pdf_path)\n",
    "        results[eleve_id] = extractions[0] if extractions else None\n",
    "    except Exception as e:\n",
    "        results[eleve_id] = f\"ERROR: {e}\"\n",
    "    times[eleve_id] = time.perf_counter() - start\n",
    "\n",
    "    status = \"OK\" if not isinstance(results[eleve_id], str) else \"ERREUR\"\n",
    "    print(f\"{eleve_id}: {times[eleve_id]:.2f}s [{status}]\")\n",
    "\n",
    "print(f\"\\nTemps total: {sum(times.values()):.2f}s\")\n",
    "print(f\"Temps moyen: {sum(times.values())/len(times):.2f}s/PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un exemple de résultat\n",
    "exemple_id = list(results.keys())[0]\n",
    "exemple = results[exemple_id]\n",
    "\n",
    "if exemple and not isinstance(exemple, str):\n",
    "    print(f\"=== {exemple_id} ===\")\n",
    "    print(\"raw_text (500 premiers chars):\")\n",
    "    print(exemple.raw_text[:500] if exemple.raw_text else \"(vide)\")\n",
    "    print(f\"\\nraw_tables: {len(exemple.raw_tables or [])} table(s)\")\n",
    "else:\n",
    "    print(f\"Erreur: {exemple}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 3. Vérification des données extraites\n",
    "\n",
    "Les parsers retournent des données brutes (`raw_text`, `raw_tables`).\n",
    "Le post-traitement pour extraire les champs structurés sera fait par le LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé des extractions\n",
    "import pandas as pd\n",
    "\n",
    "summary = []\n",
    "for eleve_id, extraction in results.items():\n",
    "    if isinstance(extraction, str):\n",
    "        summary.append({\"eleve_id\": eleve_id, \"status\": \"ERROR\", \"raw_text_len\": 0, \"tables_count\": 0})\n",
    "    elif extraction:\n",
    "        summary.append({\n",
    "            \"eleve_id\": eleve_id,\n",
    "            \"status\": \"OK\",\n",
    "            \"raw_text_len\": len(extraction.raw_text or \"\"),\n",
    "            \"tables_count\": len(extraction.raw_tables or []),\n",
    "        })\n",
    "    else:\n",
    "        summary.append({\"eleve_id\": eleve_id, \"status\": \"EMPTY\", \"raw_text_len\": 0, \"tables_count\": 0})\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Prochaines étapes\n",
    "\n",
    "- [ ] Pseudonymisation (optionnel, si envoi cloud)\n",
    "- [ ] Stockage DuckDB\n",
    "- [ ] Génération LLM des synthèses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
