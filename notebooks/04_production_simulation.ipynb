{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Simulation Production\n",
    "\n",
    "Notebook de simulation du flow de production Chiron.\n",
    "\n",
    "## Flow complet\n",
    "```\n",
    "PDF original\n",
    "    │\n",
    "    ▼\n",
    "1. Extraction nom (pdfplumber + regex)      [local, rapide]\n",
    "    │\n",
    "    ▼\n",
    "2. NER pour variantes (CamemBERT)           [local, ~0.4s]\n",
    "    │\n",
    "    ▼\n",
    "3. Anonymisation PDF (PyMuPDF redaction)    [local, rapide]\n",
    "    │\n",
    "    ▼\n",
    "4. OCR (Mistral OCR)                        [cloud, ~2s]\n",
    "    │\n",
    "    ▼\n",
    "5. Données structurées (EleveExtraction)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E402\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Auto-détecter project_root\n",
    "current = Path.cwd()\n",
    "while current != current.parent:\n",
    "    if (current / \"pyproject.toml\").exists():\n",
    "        project_root = current\n",
    "        break\n",
    "    current = current.parent\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(project_root / \".env\")\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = project_root / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"PDFs disponibles: {[p.name for p in RAW_DIR.glob('*.pdf')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et estimation des coûts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.document import estimate_mistral_cost\n",
    "from src.llm.config import settings\n",
    "\n",
    "# Afficher la config actuelle\n",
    "print(f\"Modèle Mistral OCR : {settings.mistral_ocr_model}\")\n",
    "print(f\"Coût Mistral OCR : {settings.mistral_ocr_cost_per_1000_pages}$/1000 pages\")\n",
    "\n",
    "# Estimation du coût\n",
    "pdfs = [p for p in RAW_DIR.glob(\"*.pdf\") if not p.name.startswith(\"ELEVE_TEST\")]\n",
    "estimate = estimate_mistral_cost(pdfs)\n",
    "print(f\"\\nPDFs à traiter : {len(pdfs)}\")\n",
    "print(f\"Pages totales : {estimate['pages']}\")\n",
    "print(f\"Coût estimé Mistral OCR : ${estimate['cost_usd']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des modèles NER\n",
    "\n",
    "CamemBERT v1 (`Jean-Baptiste/camembert-ner`) est utilisé pour détecter les variantes du nom de l'élève."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Charger CamemBERT NER (meilleur compromis vitesse/précision)\n",
    "print(\"Chargement de CamemBERT NER...\")\n",
    "nlp_ner = pipeline(\n",
    "    \"ner\",\n",
    "    model=\"Jean-Baptiste/camembert-ner\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "print(\"✅ CamemBERT NER chargé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonctions d'anonymisation\n",
    "\n",
    "Ces fonctions permettent :\n",
    "1. D'extraire le nom de l'élève depuis l'en-tête du PDF\n",
    "2. De détecter toutes les variantes avec NER\n",
    "3. D'anonymiser le PDF avant envoi cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import re\n\nimport fitz  # PyMuPDF\nimport pdfplumber\n\n\ndef extract_eleve_name(pdf_path: Path) -> dict | None:\n    \"\"\"Extrait le nom de l'élève depuis le PDF.\n\n    Recherche le pattern \"Élève : <nom>\" et capture le texte jusqu'à la fin de la ligne.\n\n    Args:\n        pdf_path: Chemin vers le fichier PDF.\n\n    Returns:\n        Dict avec 'nom_complet' et 'texte_complet', ou None si non trouvé.\n    \"\"\"\n    with pdfplumber.open(pdf_path) as pdf:\n        text_complet = \"\"\n        for page in pdf.pages:\n            text_complet += (page.extract_text() or \"\") + \"\\n\"\n\n        match = re.search(r\"[ÉE]l[èe]ve\\s*:\\s*([^\\n]+)\", text_complet, re.IGNORECASE)\n        if match:\n            return {\n                \"nom_complet\": match.group(1).strip(),\n                \"texte_complet\": text_complet,\n            }\n    return None\n\n\ndef split_into_chunks(text: str, max_chars: int = 2000) -> list[str]:\n    \"\"\"Découpe le texte en chunks en respectant les fins de phrases.\n\n    Args:\n        text: Texte à découper\n        max_chars: Taille max par chunk (~2000 chars ≈ 400 tokens pour CamemBERT)\n\n    Returns:\n        Liste de chunks\n    \"\"\"\n    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n\n    chunks = []\n    current_chunk = \"\"\n\n    for sentence in sentences:\n        if len(current_chunk) + len(sentence) < max_chars:\n            current_chunk += sentence + \" \"\n        else:\n            if current_chunk:\n                chunks.append(current_chunk.strip())\n            current_chunk = sentence + \" \"\n\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n\n    return chunks if chunks else [text]\n\n\ndef detect_name_variants(text: str, nom_entete: str, nlp_pipeline) -> list[str]:\n    \"\"\"Détecte toutes les variantes du nom de l'élève avec NER.\n\n    Args:\n        text: Texte complet du PDF\n        nom_entete: Nom extrait de l'en-tête (\"Élève : XXX\")\n        nlp_pipeline: Pipeline NER (CamemBERT)\n\n    Returns:\n        Liste des variantes uniques, triées par longueur décroissante\n    \"\"\"\n    # Labels pour les personnes\n    person_labels = {\"PER\", \"PERSON\", \"I-PER\", \"B-PER\"}\n\n    # Extraire les personnes avec NER\n    chunks = split_into_chunks(text, max_chars=2000)\n    personnes = []\n    for chunk in chunks:\n        entities = nlp_pipeline(chunk)\n        for e in entities:\n            if e[\"entity_group\"].upper() in person_labels or \"PER\" in e[\"entity_group\"].upper():\n                personnes.append(e[\"word\"])\n\n    # Filtrer les variantes qui correspondent au nom de l'en-tête\n    nom_parts = [p.lower() for p in nom_entete.strip().split()]\n    variants = set()\n\n    for personne in set(personnes):\n        personne_clean = personne.strip()\n        if not personne_clean:\n            continue\n        personne_parts = personne_clean.lower().split()\n        # Match si au moins une partie correspond\n        if any(part in nom_parts for part in personne_parts):\n            variants.add(personne_clean)\n\n    # Toujours inclure le nom complet\n    variants.add(nom_entete.strip())\n\n    # Trier par longueur décroissante (remplacer les plus longs d'abord)\n    return sorted(variants, key=len, reverse=True)\n\n\ndef anonymize_pdf(pdf_path: Path, noms_a_remplacer: list[str], nom_anonyme: str) -> bytes:\n    \"\"\"Remplace les noms dans le PDF et retourne les bytes du PDF anonymisé.\n\n    Args:\n        pdf_path: Chemin vers le PDF original\n        noms_a_remplacer: Liste des variantes du nom à remplacer\n        nom_anonyme: Nom de remplacement (ex: \"ELEVE_001\")\n\n    Returns:\n        Bytes du PDF anonymisé\n    \"\"\"\n    fitz.TOOLS.set_small_glyph_heights(True)\n\n    doc = fitz.open(pdf_path)\n    total_replacements = 0\n\n    for page in doc:\n        for nom in noms_a_remplacer:\n            instances = page.search_for(nom)\n            for rect in instances:\n                page.add_redact_annot(\n                    rect,\n                    text=nom_anonyme,\n                    fill=(1, 1, 1),\n                    fontsize=10,\n                )\n                total_replacements += 1\n        page.apply_redactions()\n\n    return doc.tobytes(), total_replacements\n\n\nprint(\"✅ Fonctions d'anonymisation définies\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fonction d'extraction Mistral OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "\n",
    "from mistralai import Mistral\n",
    "\n",
    "# Init client Mistral\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\") or os.getenv(\"MISTRAL_OCR_API_KEY\")\n",
    "if not mistral_api_key:\n",
    "    raise ValueError(\"MISTRAL_API_KEY ou MISTRAL_OCR_API_KEY non configurée dans .env\")\n",
    "\n",
    "mistral_client = Mistral(api_key=mistral_api_key)\n",
    "mistral_model = settings.mistral_ocr_model\n",
    "\n",
    "\n",
    "def extract_with_mistral_ocr(pdf_bytes: bytes) -> dict:\n",
    "    \"\"\"Extrait le contenu d'un PDF avec Mistral OCR.\n",
    "\n",
    "    Args:\n",
    "        pdf_bytes: Bytes du PDF (peut être anonymisé)\n",
    "\n",
    "    Returns:\n",
    "        Dict avec le résultat OCR (pages, markdown, etc.)\n",
    "    \"\"\"\n",
    "    base64_pdf = base64.b64encode(pdf_bytes).decode(\"utf-8\")\n",
    "\n",
    "    response = mistral_client.ocr.process(\n",
    "        model=mistral_model,\n",
    "        document={\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\": f\"data:application/pdf;base64,{base64_pdf}\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return json.loads(response.model_dump_json())\n",
    "\n",
    "\n",
    "print(f\"✅ Client Mistral initialisé (modèle: {mistral_model})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline complet : Anonymisation + OCR\n",
    "\n",
    "Traitement de tous les PDFs avec le flow complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Résultats\n",
    "results = {}\n",
    "timings = {}\n",
    "\n",
    "# Filtrer les PDFs de test\n",
    "pdfs_to_process = [p for p in sorted(RAW_DIR.glob(\"*.pdf\")) if not p.name.startswith(\"ELEVE_TEST\")]\n",
    "\n",
    "print(f\"Traitement de {len(pdfs_to_process)} PDFs...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for pdf_path in pdfs_to_process:\n",
    "    eleve_id = pdf_path.stem\n",
    "    print(f\"\\n[{eleve_id}]\")\n",
    "\n",
    "    timing = {}\n",
    "    start_total = time.perf_counter()\n",
    "\n",
    "    try:\n",
    "        # 1. Extraire le nom depuis l'en-tête\n",
    "        start = time.perf_counter()\n",
    "        eleve_info = extract_eleve_name(pdf_path)\n",
    "        timing[\"extract_name\"] = time.perf_counter() - start\n",
    "\n",
    "        if not eleve_info:\n",
    "            print(\"  ⚠️ Nom non trouvé dans l'en-tête\")\n",
    "            results[eleve_id] = {\"error\": \"Nom non trouvé\"}\n",
    "            continue\n",
    "\n",
    "        nom_original = eleve_info[\"nom_complet\"]\n",
    "        print(f\"  1. Nom extrait: '{nom_original}' ({timing['extract_name']:.3f}s)\")\n",
    "\n",
    "        # 2. Détecter les variantes avec NER\n",
    "        start = time.perf_counter()\n",
    "        variants = detect_name_variants(eleve_info[\"texte_complet\"], nom_original, nlp_ner)\n",
    "        timing[\"ner\"] = time.perf_counter() - start\n",
    "        print(f\"  2. Variantes NER: {variants} ({timing['ner']:.3f}s)\")\n",
    "\n",
    "        # 3. Anonymiser le PDF\n",
    "        start = time.perf_counter()\n",
    "        nom_anonyme = eleve_id  # Utiliser l'ID du fichier comme pseudonyme\n",
    "        pdf_anonymise, nb_replacements = anonymize_pdf(pdf_path, variants, nom_anonyme)\n",
    "        timing[\"anonymize\"] = time.perf_counter() - start\n",
    "        print(f\"  3. Anonymisation: {nb_replacements} remplacements ({timing['anonymize']:.3f}s)\")\n",
    "\n",
    "        # 4. Envoyer à Mistral OCR\n",
    "        start = time.perf_counter()\n",
    "        ocr_result = extract_with_mistral_ocr(pdf_anonymise)\n",
    "        timing[\"ocr\"] = time.perf_counter() - start\n",
    "        markdown = ocr_result[\"pages\"][0][\"markdown\"]\n",
    "        print(f\"  4. Mistral OCR: {len(markdown)} chars ({timing['ocr']:.3f}s)\")\n",
    "\n",
    "        # 5. Vérifier l'anonymisation\n",
    "        anonymisation_ok = True\n",
    "        for variant in variants:\n",
    "            if variant.lower() in markdown.lower():\n",
    "                print(f\"  ⚠️ '{variant}' encore présent dans le résultat OCR!\")\n",
    "                anonymisation_ok = False\n",
    "\n",
    "        if anonymisation_ok:\n",
    "            print(\"  ✅ Anonymisation vérifiée\")\n",
    "\n",
    "        # Stocker le résultat\n",
    "        timing[\"total\"] = time.perf_counter() - start_total\n",
    "        results[eleve_id] = {\n",
    "            \"nom_original\": nom_original,\n",
    "            \"nom_anonyme\": nom_anonyme,\n",
    "            \"variants\": variants,\n",
    "            \"nb_replacements\": nb_replacements,\n",
    "            \"markdown\": markdown,\n",
    "            \"anonymisation_ok\": anonymisation_ok,\n",
    "        }\n",
    "        timings[eleve_id] = timing\n",
    "\n",
    "        print(f\"  → Total: {timing['total']:.2f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erreur: {e}\")\n",
    "        results[eleve_id] = {\"error\": str(e)}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Traitement terminé: {len(results)} PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Résumé des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tableau récapitulatif\n",
    "summary = []\n",
    "for eleve_id, result in results.items():\n",
    "    if \"error\" in result:\n",
    "        summary.append({\n",
    "            \"eleve_id\": eleve_id,\n",
    "            \"status\": \"❌ ERREUR\",\n",
    "            \"nom_original\": \"-\",\n",
    "            \"nb_variants\": 0,\n",
    "            \"nb_replacements\": 0,\n",
    "            \"anonymisation_ok\": \"-\",\n",
    "            \"temps_total\": \"-\",\n",
    "        })\n",
    "    else:\n",
    "        summary.append({\n",
    "            \"eleve_id\": eleve_id,\n",
    "            \"status\": \"✅ OK\",\n",
    "            \"nom_original\": result[\"nom_original\"],\n",
    "            \"nb_variants\": len(result[\"variants\"]),\n",
    "            \"nb_replacements\": result[\"nb_replacements\"],\n",
    "            \"anonymisation_ok\": \"✅\" if result[\"anonymisation_ok\"] else \"❌\",\n",
    "            \"temps_total\": f\"{timings[eleve_id]['total']:.2f}s\",\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "print(\"RÉSUMÉ DU TRAITEMENT\")\n",
    "print(\"=\" * 80)\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détail des temps\n",
    "if timings:\n",
    "    df_times = pd.DataFrame([\n",
    "        {\n",
    "            \"eleve_id\": eleve_id,\n",
    "            \"extract_name\": f\"{t['extract_name']:.3f}s\",\n",
    "            \"ner\": f\"{t['ner']:.3f}s\",\n",
    "            \"anonymize\": f\"{t['anonymize']:.3f}s\",\n",
    "            \"ocr\": f\"{t['ocr']:.3f}s\",\n",
    "            \"total\": f\"{t['total']:.2f}s\",\n",
    "        }\n",
    "        for eleve_id, t in timings.items()\n",
    "    ])\n",
    "\n",
    "    print(\"\\nDÉTAIL DES TEMPS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_times.to_string(index=False))\n",
    "\n",
    "    # Moyennes\n",
    "    avg_total = sum(t[\"total\"] for t in timings.values()) / len(timings)\n",
    "    avg_ocr = sum(t[\"ocr\"] for t in timings.values()) / len(timings)\n",
    "    avg_ner = sum(t[\"ner\"] for t in timings.values()) / len(timings)\n",
    "    print(f\"\\nMoyennes: NER={avg_ner:.2f}s, OCR={avg_ocr:.2f}s, Total={avg_total:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Afficher un exemple de résultat OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le markdown d'un exemple\n",
    "exemple_id = list(results.keys())[0]\n",
    "exemple = results[exemple_id]\n",
    "\n",
    "if \"markdown\" in exemple:\n",
    "    print(f\"=== {exemple_id} (anonymisé en '{exemple['nom_anonyme']}') ===\")\n",
    "    print(f\"Nom original: {exemple['nom_original']}\")\n",
    "    print(f\"Variantes détectées: {exemple['variants']}\")\n",
    "    print(\"\\n--- Markdown OCR (premiers 1500 chars) ---\\n\")\n",
    "    print(exemple[\"markdown\"][:1500])\n",
    "else:\n",
    "    print(f\"Erreur: {exemple}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prochaines étapes\n",
    "\n",
    "- [ ] Parser le markdown en `EleveExtraction` structuré\n",
    "- [ ] Stockage DuckDB (avec pseudonymisation)\n",
    "- [ ] Génération LLM des synthèses\n",
    "- [ ] Dépseudonymisation pour export"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
